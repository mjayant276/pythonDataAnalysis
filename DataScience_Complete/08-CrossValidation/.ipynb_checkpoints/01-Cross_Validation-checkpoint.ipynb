{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PW2BVrHCY4wE"
   },
   "source": [
    "# 1. Hold Out Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "odIhGyTkXpeX"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mZjjmH-EZMT_",
    "outputId": "a5a93405-dba7-422d-fc29-c88de5cc6409"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training dataset is : 0.9619047619047619\n",
      "Accuracy on test dataset is : 1.0\n"
     ]
    }
   ],
   "source": [
    "# not suitable for imbalanced dataset\n",
    "# 80% - Class 0\n",
    "# 20% - class 1\n",
    "\n",
    "# Large chunk of data gets deprived of training of model(small dataset)\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "log = LogisticRegression()  \n",
    "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "\n",
    "log.fit(x_train,y_train)\n",
    "\n",
    "y_pred = log.predict(x_test)\n",
    "\n",
    "print(f\"Accuracy on training dataset is : {accuracy_score(y_train,log.predict(x_train))}\")\n",
    "print(f\"Accuracy on test dataset is : {accuracy_score(y_test,log.predict(x_test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UTBjLLucP6L"
   },
   "source": [
    "# K-Fold Cross Validation Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "esrQbh5XcFAY"
   },
   "outputs": [],
   "source": [
    "# k - parts\n",
    "# 1 Fold - Validation\n",
    "# K-1 fold for training dataset\n",
    "\n",
    "# Pros \n",
    "# Cons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4tnSUOu0cyPw",
    "outputId": "33d73ae4-ce60-4882-d798-251b3812a1c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation scores are : [1.         1.         0.86666667 0.93333333 0.83333333]\n",
      "Average Cross Validation scores is : 0.9266666666666665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jayanth\\anaconda3\\envs\\daskenv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jayanth\\anaconda3\\envs\\daskenv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jayanth\\anaconda3\\envs\\daskenv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score,KFold\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "score = cross_val_score(log,X,y,cv=kf)\n",
    "print(f\"Cross Validation scores are : {score}\")\n",
    "print(f\"Average Cross Validation scores is : {score.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RpwuKc0xdVjw"
   },
   "source": [
    "# Stratified K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6gMR2MzPdJ-u",
    "outputId": "466c23b1-20ce-4a15-d5d6-0893b15778a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\n",
      "TRAIN: [1 3] TEST: [0 2]\n",
      "TRAIN: [0 2] TEST: [1 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([0, 0, 1, 1])\n",
    "skf = StratifiedKFold(n_splits=2)\n",
    "skf.get_n_splits(X, y)\n",
    "\n",
    "print(skf)\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIHBcx3akiDu"
   },
   "source": [
    "# Leave P Out Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hrIudGH_jywE",
    "outputId": "1f7752eb-6550-4ba2-a6ec-c4ed0fd49410"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeavePOut(p=2)\n",
      "TRAIN: [2 3] TEST: [0 1]\n",
      "TRAIN: [1 3] TEST: [0 2]\n",
      "TRAIN: [1 2] TEST: [0 3]\n",
      "TRAIN: [0 3] TEST: [1 2]\n",
      "TRAIN: [0 2] TEST: [1 3]\n",
      "TRAIN: [0 1] TEST: [2 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import LeavePOut\n",
    "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
    "y = np.array([1, 2, 3, 4])\n",
    "lpo = LeavePOut(2)\n",
    "lpo.get_n_splits(X)\n",
    "\n",
    "print(lpo)\n",
    "\n",
    "for train_index, test_index in lpo.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ye92hCuVlQIp"
   },
   "source": [
    "#Leave One Out Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hRjqdsa6lKLT",
    "outputId": "267ddf44-fd04-46fc-f160-b624bb4210b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeaveOneOut()\n",
      "TRAIN: [1] TEST: [0]\n",
      "[[3 4]] [[1 2]] [2] [1]\n",
      "TRAIN: [0] TEST: [1]\n",
      "[[1 2]] [[3 4]] [1] [2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "X = np.array([[1, 2], [3, 4]])\n",
    "y = np.array([1, 2])\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(X)\n",
    "\n",
    "print(loo)\n",
    "\n",
    "for train_index, test_index in loo.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFkBpsuMl7DN"
   },
   "source": [
    "# ShuffleSplit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_0r8laOUlbLK",
    "outputId": "e421a569-50be-47d5-f87b-ec287820837e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=5, random_state=0, test_size=0.25, train_size=None)\n",
      "TRAIN: [1 3 0 4] TEST: [5 2]\n",
      "TRAIN: [4 0 2 5] TEST: [1 3]\n",
      "TRAIN: [1 2 4 0] TEST: [3 5]\n",
      "TRAIN: [3 4 1 0] TEST: [5 2]\n",
      "TRAIN: [3 5 1 0] TEST: [2 4]\n",
      "TRAIN: [1 3 0] TEST: [5 2]\n",
      "TRAIN: [4 0 2] TEST: [1 3]\n",
      "TRAIN: [1 2 4] TEST: [3 5]\n",
      "TRAIN: [3 4 1] TEST: [5 2]\n",
      "TRAIN: [3 5 1] TEST: [2 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [3, 4], [5, 6]])\n",
    "y = np.array([1, 2, 1, 2, 1, 2])\n",
    "rs = ShuffleSplit(n_splits=5, test_size=.25, random_state=0)\n",
    "rs.get_n_splits(X)\n",
    "\n",
    "print(rs)\n",
    "\n",
    "for train_index, test_index in rs.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rs = ShuffleSplit(n_splits=5, train_size=0.5, test_size=.25,\n",
    "                  random_state=0)\n",
    "for train_index, test_index in rs.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_IzPyOnmRZi"
   },
   "source": [
    "# Time Series Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "K3mVRdtbl9BP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None)\n",
      "TRAIN: [0] TEST: [1]\n",
      "TRAIN: [0 1] TEST: [2]\n",
      "TRAIN: [0 1 2] TEST: [3]\n",
      "TRAIN: [0 1 2 3] TEST: [4]\n",
      "TRAIN: [0 1 2 3 4] TEST: [5]\n",
      "TRAIN: [0 1 2 3 4 5] TEST: [6 7]\n",
      "TRAIN: [0 1 2 3 4 5 6 7] TEST: [8 9]\n",
      "TRAIN: [0 1 2 3 4 5 6 7 8 9] TEST: [10 11]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([1, 2, 3, 4, 5, 6])\n",
    "tscv = TimeSeriesSplit()\n",
    "print(tscv)\n",
    "\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Fix test_size to 2 with 12 samples\n",
    "X = np.random.randn(12, 2)\n",
    "y = np.random.randint(0, 2, 12)\n",
    "tscv = TimeSeriesSplit(n_splits=3, test_size=2)\n",
    "for train_index, test_index in tscv.split(X):\n",
    "   print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "   X_train, X_test = X[train_index], X[test_index]\n",
    "   y_train, y_test = y[train_index], y[test_index]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
