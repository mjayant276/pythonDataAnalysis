{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47f40742",
   "metadata": {},
   "source": [
    "<img src=\"images/dask_horizontal.svg\"\n",
    "     width=\"45%\"\n",
    "     alt=\"Dask logo\\\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8b0819",
   "metadata": {},
   "source": [
    "## What Is Dask?\n",
    "- Dask was created by <b>Matthew Rocklin</b> in December 2014 \n",
    "- Dask is a parallel and distributed computing library that scales the existing Python and PyData ecosystem\n",
    "- is an open source library that provides efficient parallelization in ML and data analytics.\n",
    "- Dask helps developers scale their entire Python ecosystem, and it can work with your laptop or a container cluster\n",
    "- Dask is designed to scale the existing Python ecosystem.\n",
    "- Dask is used in Climate Science, Energy, Hydrology, Meteorology, and Satellite Imaging\n",
    "</br>\n",
    "##### There are many parts to the \"Dask\" the project:\n",
    "* Collections/API also known as \"core-library\".\n",
    "* Distributed -- to create clusters\n",
    "* Intergrations and broader ecosystem\n",
    "</br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b86a06",
   "metadata": {},
   "source": [
    "### Dask Collections\n",
    "\n",
    "​\n",
    "\n",
    "Dask provides **multi-core** and **distributed+parallel** execution on **larger-than-memory** datasets\n",
    "\n",
    "​\n",
    "\n",
    "We can think of Dask's APIs (also called collections)  at a high and a low level:\n",
    "\n",
    "​\n",
    "\n",
    "<center>\n",
    "\n",
    "<img src=\"images/high_vs_low_level_coll_analogy.png\" width=\"75%\" alt=\"High vs Low level clothes analogy\">\n",
    "\n",
    "</center>\n",
    "\n",
    "​\n",
    "\n",
    "*  **High-level collections:**  Dask provides high-level Array, Bag, and DataFrame\n",
    "\n",
    "   collections that mimic NumPy, lists, and pandas but can operate in parallel on\n",
    "\n",
    "   datasets that don't fit into memory.\n",
    "\n",
    "* **Low-level collections:**  Dask also provides low-level Delayed and Futures\n",
    "\n",
    "   collections that give you finer control to build custom parallel and distributed computations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b530cf",
   "metadata": {},
   "source": [
    "### Dask Cluster\n",
    "\n",
    "Most of the times when you are using Dask, you will be using a distributed scheduler, which exists in the context of a Dask cluster. The Dask cluster is structured as:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/distributed-overview.png\" width=\"75%\" alt=\"Distributed overview\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2722cf3",
   "metadata": {},
   "source": [
    "### Dask Ecosystem\n",
    "\n",
    "In addition to the core Dask library and its distributed scheduler, the Dask ecosystem connects several additional initiatives, including:\n",
    "\n",
    "<h6>Array</h6>\n",
    "\n",
    "- xarray: Wraps Dask Array, offering the same scalability, but with axis labels which add convenience when dealing with complex datasets.\n",
    "- cupy: Part of the Rapids project, GPU-enabled arrays can be used as the blocks of Dask Arrays. See the section GPUs for more information.\n",
    "- sparse: Implements sparse arrays of arbitrary dimension on top of numpy and scipy.sparse.\n",
    "- pint: Allows arithmetic operations between them and conversions from and to different units.\n",
    "\n",
    "\n",
    "<h6>DataFrame</h6>\n",
    "\n",
    "- cudf: Part of the Rapids project, implements GPU-enabled dataframes which can be used as partitions in Dask Dataframes.\n",
    "\n",
    "- dask-geopandas: Early-stage subproject of geopandas, enabling parallelization of geopandas dataframes.\n",
    "\n",
    "\n",
    "<h6>SQL</h6>\n",
    "\n",
    "- blazingSQL: Part of the Rapids project, implements SQL queries using cuDF and Dask, for execution on CUDA/GPU-enabled hardware, including referencing externally-stored data.\n",
    "\n",
    "- dask-sql: Adds a SQL query layer on top of Dask. The API matches blazingSQL but it uses CPU instead of GPU. It still under development and not ready for a production use-case.\n",
    "\n",
    "- fugue-sql: Adds an abstract layer that makes code portable between across differing computing frameworks such as Pandas, Spark and Dask.\n",
    "\n",
    "\n",
    "<h6>Machine Learning</h6>\n",
    "\n",
    "- dask-ml: Implements distributed versions of common machine learning algorithms.\n",
    "\n",
    "- scikit-learn: Provide ‘dask’ to the joblib backend to parallelize scikit-learn algorithms with dask as the processor.\n",
    "\n",
    "- xgboost: Powerful and popular library for gradient boosted trees; includes native support for distributed training using dask.\n",
    "\n",
    "- lightgbm: Similar to XGBoost; lightgmb also natively supplies native distributed training for decision trees.\n",
    "\n",
    "\n",
    "<h6>Deploying Dask</h6>\n",
    "\n",
    "There are many different implementations of the Dask distributed cluster.\n",
    "\n",
    "- dask-jobqueue: Deploy Dask on job queuing systems like PBS, Slurm, MOAB, SGE, LSF, and HTCondor.\n",
    "\n",
    "- dask-kubernetes: Deploy Dask workers on Kubernetes from within a Python script or interactive session.\n",
    "\n",
    "- dask-helm: Deploy Dask and (optionally) Jupyter or JupyterHub on Kubernetes easily using Helm.\n",
    "\n",
    "- dask-yarn / Hadoop: Deploy Dask on YARN clusters, such as are found in traditional Hadoop installations.\n",
    "\n",
    "- dask-cloudprovider: Deploy Dask on various cloud platforms such as AWS, Azure, and GCP leveraging cloud native APIs.\n",
    "\n",
    "- dask-gateway: Secure, multi-tenant server for managing Dask clusters. Launch and use Dask clusters in a shared, centrally managed cluster environment, without requiring users to have direct access to the underlying cluster backend.\n",
    "\n",
    "- dask-cuda: Construct a Dask cluster which resembles LocalCluster and is specifically optimized for GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ca4de8",
   "metadata": {},
   "source": [
    "#### Components of Dask\n",
    "1. **Dask collections** which extend common interfaces like NumPy, pandas, and Python iterators to larger-than-memory or distributed environments by creating *task graphs*\n",
    "2. **Schedulers** which compute task graphs produced by Dask collections in parallel\n",
    "\n",
    "<img src=\"images/dask-overview.png\"\n",
    "     width=\"85%\"\n",
    "     alt=\"Dask components\\\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de8f28b",
   "metadata": {},
   "source": [
    "## Why use Dask?\n",
    "- Enables parallel and larger-than-memory computations\n",
    "- Uses familiar APIs you're used to from projects like NumPy, pandas, and scikit-learn\n",
    "- Allows you to scale existing workflows with minimal code changes\n",
    "- Dask works on your laptop, but also scales out to large clusters\n",
    "- Offers great built-in diagnosic tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8176561",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
